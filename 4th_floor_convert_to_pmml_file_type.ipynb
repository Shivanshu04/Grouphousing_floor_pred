{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwDEPadAV874hX0zDJLnxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivanshu04/Grouphousing_floor_pred/blob/main/4th_floor_convert_to_pmml_file_type.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMdl52kU1OEY",
        "outputId": "194a5a0b-4eae-4878-dcb4-9cf2f5828134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn2pmml\n",
            "  Downloading sklearn2pmml-0.98.1.tar.gz (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dill>=0.3.4 (from sklearn2pmml)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from sklearn2pmml) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from sklearn2pmml) (1.2.2)\n",
            "Requirement already satisfied: sklearn-pandas>=0.0.10 in /usr/local/lib/python3.10/dist-packages (from sklearn2pmml) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->sklearn2pmml) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->sklearn2pmml) (1.11.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->sklearn2pmml) (3.2.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from sklearn-pandas>=0.0.10->sklearn2pmml) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (1.16.0)\n",
            "Building wheels for collected packages: sklearn2pmml\n",
            "  Building wheel for sklearn2pmml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn2pmml: filename=sklearn2pmml-0.98.1-py3-none-any.whl size=7051306 sha256=c22f22503473cf0b08aa8f69aee479fe262d0e5ae5a2430cb225013b6b5a3100\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/44/b2/48ffeecd45f409ea55fb0c10fa56023efb8432cb9deb679a82\n",
            "Successfully built sklearn2pmml\n",
            "Installing collected packages: dill, sklearn2pmml\n",
            "Successfully installed dill-0.3.7 sklearn2pmml-0.98.1\n"
          ]
        }
      ],
      "source": [
        "pip install sklearn2pmml\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn2pmml import sklearn2pmml, PMMLPipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Define the file path to the dataset\n",
        "file_path = '/content/4th_floor_with_estimated_durations_final_output.csv'\n",
        "\n",
        "# Re-loading the dataset\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "# Converting date columns to datetime objects\n",
        "data['actual_commencement_date'] = pd.to_datetime(data['actual_commencement_date'], errors='coerce')\n",
        "data['estimated_finish_date'] = pd.to_datetime(data['estimated_finish_date'], errors='coerce')\n",
        "\n",
        "# Creating new features based on the date columns\n",
        "current_date = datetime.now()\n",
        "data['duration_until_estimated_finish'] = (data['estimated_finish_date'] - data['actual_commencement_date']).dt.days\n",
        "data['duration_since_commencement'] = (current_date - data['actual_commencement_date']).dt.days\n",
        "data['remaining_duration'] = (data['estimated_finish_date'] - current_date).dt.days\n",
        "data['progress_ratio'] = data['duration_since_commencement'] / data['duration_until_estimated_finish']\n",
        "\n",
        "# Handling missing values in the 'current_stage' column\n",
        "data.loc[(data['current_stage'].isna()) & (data['Project_status'] == 'Completed'), 'current_stage'] = 'Handover'\n",
        "\n",
        "# Step 3: Feature Engineering\n",
        "# Creating new features\n",
        "data['year_of_commencement'] = data['actual_commencement_date'].dt.year\n",
        "data['month_of_commencement'] = data['actual_commencement_date'].dt.month\n",
        "data['year_of_estimated_finish'] = data['estimated_finish_date'].dt.year\n",
        "data['month_of_estimated_finish'] = data['estimated_finish_date'].dt.month\n",
        "data['days_exceeding_estimated_duration'] = data['duration_since_commencement'] - data['duration_until_estimated_finish']\n",
        "data['is_delayed'] = (data['remaining_duration'] < 0).astype(int)\n",
        "\n",
        "# Handling other missing values with appropriate strategies\n",
        "data.fillna(data.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Performing label encoding on the 'current_stage' column\n",
        "label_encoder = LabelEncoder()\n",
        "data['current_stage'] = data['current_stage'].astype(str) # Converting to string to handle any NaN values left\n",
        "data['current_stage_encoded'] = label_encoder.fit_transform(data['current_stage'])\n",
        "\n",
        "# Step 4: Data Splitting\n",
        "# Selecting relevant features for the model\n",
        "feature_columns = [\n",
        "    'duration_until_estimated_finish', 'duration_since_commencement', 'remaining_duration',\n",
        "    'progress_ratio', 'year_of_commencement', 'month_of_commencement',\n",
        "    'year_of_estimated_finish', 'month_of_estimated_finish',\n",
        "    'days_exceeding_estimated_duration', 'is_delayed'\n",
        "]\n",
        "\n",
        "# Defining the feature set and the target variable\n",
        "X = data[feature_columns]\n",
        "y = data['current_stage_encoded']\n",
        "\n",
        "# Splitting the data into training and testing sets (80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Displaying a message to indicate the preprocessing steps are completed\n",
        "\"Data preprocessing and splitting completed successfully.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tz3HK0uxUhMn",
        "outputId": "560a9192-ae88-43ad-f961-10a4766e2fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data preprocessing and splitting completed successfully.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initializing and training the Gradient Boosting Classifier\n",
        "gbm_model = GradientBoostingClassifier(random_state=42)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Displaying a message to indicate that the model has been trained\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "2I9Tap8B1sPg",
        "outputId": "0e683c52-894f-45d8-d0a1-e42cd9bceebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Predicting the current stage on the testing set\n",
        "y_pred = gbm_model.predict(X_test)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Getting the classification report\n",
        "class_report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
        "\n",
        "accuracy, class_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "2eTohg4a2Awt",
        "outputId": "fbe87ff8-2a6f-4ec3-8e69-cd4bd28ab477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2f690c45e0d7>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Getting the classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclass_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2330\u001b[0m             )\n\u001b[1;32m   2331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2333\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 24, does not match size of target_names, 26. Try specifying the labels parameter"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the unique labels present in the test set to avoid mismatch issue\n",
        "unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
        "\n",
        "# Getting the classification report with the correct labels\n",
        "class_report = classification_report(y_test, y_pred, labels=unique_labels, target_names=label_encoder.classes_[unique_labels])\n",
        "\n",
        "accuracy, class_report\n",
        "# Create a PMMLPipeline with the trained model\n",
        "pipeline = PMMLPipeline([(\"classifier\", gbm_model)])\n",
        "# Export the pipeline to a PMML file\n",
        "sklearn2pmml(pipeline, \"gbm_model.pmml\", with_repr=True)"
      ],
      "metadata": {
        "id": "zhVmFaQr11SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the unique stage names in the main dataset and the materials data file\n",
        "import pandas as pd\n",
        "\n",
        "materials_data = pd.read_csv(\"/content/Copy of stage_with materai.csv\")\n",
        "unique_stages_main_dataset = data['current_stage'].unique()\n",
        "unique_stages_materials_data = materials_data['Activity'].unique()\n",
        "\n",
        "unique_stages_main_dataset, unique_stages_materials_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5xYarUl2M4K",
        "outputId": "961e3e45-5bc9-4fd2-abff-60aaeaa8c978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['Handover',\n",
              "        'Plumbing & Sanitary,Electrification Works_estimated_duration',\n",
              "        'Plastering on outer sides_estimated_duration',\n",
              "        'Painting and Finishing_estimated_duration',\n",
              "        '3rd Floor slab casting_estimated_duration',\n",
              "        'Electrical concealed, PVC Fitting, plastering at 1st-4th floor_estimated_duration',\n",
              "        'nan', 'Brick work at 1st Floor _estimated_duration',\n",
              "        '3rd floor Columns casting _estimated_duration',\n",
              "        'Tiles work_estimated_duration',\n",
              "        'Electrical concealed, PVC Fitting, plastering at ground floor_estimated_duration',\n",
              "        '4th Floor slab casting_estimated_duration',\n",
              "        'Brick work of 2nd to 4th Floor _estimated_duration',\n",
              "        'Doors & Windows Fixing Furniture work_estimated_duration',\n",
              "        'Ground Floor slab casting _estimated_duration',\n",
              "        'Cleaning & survey_estimated_duration',\n",
              "        '1st Floor slab casting_estimated_duration',\n",
              "        'Excavation,leveling & P.C.C  for Basement  B1 _estimated_duration',\n",
              "        '4th floor Columns casting _estimated_duration',\n",
              "        'Brick work at Basement to Ground Floor _estimated_duration',\n",
              "        'Slab of B (bottom) _estimated_duration',\n",
              "        'Electrical concealed, PVC Fitting, plastering at Basement_estimated_duration',\n",
              "        '2nd floor Columns casting _estimated_duration',\n",
              "        '2nd Floor slab casting_estimated_duration',\n",
              "        'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring _estimated_duration',\n",
              "        '1st floor Columns casting_estimated_duration'], dtype=object),\n",
              " array(['Cleaning & survey',\n",
              "        'Excavation,leveling & P.C.C  for Basement  B1 ',\n",
              "        ' Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring ',\n",
              "        'Slab of B (bottom) ', ' Ground Floor slab casting ',\n",
              "        ' 1st floor Columns casting', ' 1st Floor slab casting',\n",
              "        '2nd floor Columns casting ', '2nd Floor slab casting',\n",
              "        ' Brick work at Basement to Ground Floor ',\n",
              "        'Electrical concealed, PVC Fitting, plastering at Basement',\n",
              "        '3rd floor Columns casting ', '3rd Floor slab casting',\n",
              "        ' Brick work at 1st Floor ',\n",
              "        'Electrical concealed, PVC Fitting, plastering at ground floor',\n",
              "        '4th floor Columns casting ', '4th Floor slab casting',\n",
              "        ' Brick work of 2nd to 4th Floor ',\n",
              "        'Electrical concealed, PVC Fitting, plastering at 1st-4th floor',\n",
              "        'Plastering on outer sides', 'Tiles work',\n",
              "        'Painting and Finishing',\n",
              "        'Plumbing & Sanitary,Electrification Works',\n",
              "        'Doors & Windows Fixing Furniture work'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the \"_estimated_duration\" suffix from the stage names in the main dataset\n",
        "data['current_stage_cleaned'] = data['current_stage'].str.replace('_estimated_duration', '')\n",
        "\n",
        "# Updating the label encoder to use the cleaned stage names\n",
        "label_encoder = LabelEncoder()\n",
        "data['current_stage_encoded'] = label_encoder.fit_transform(data['current_stage_cleaned'].astype(str))\n",
        "\n",
        "# Creating a dictionary to map the encoded labels to the cleaned stage names\n",
        "label_to_stage_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
        "\n",
        "# Displaying the cleaned unique stage names\n",
        "cleaned_unique_stages_main_dataset = data['current_stage_cleaned'].unique()"
      ],
      "metadata": {
        "id": "5CFqtRGi2Vtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.tseries.offsets import MonthEnd\n",
        "\n",
        "# Updating the prediction function to provide predictions for the current and upcoming stages for each month\n",
        "\n",
        "# Defining the prediction function\n",
        "def predict_current_stage(inputs):\n",
        "    \"\"\"\n",
        "    Function to predict the current and upcoming stages for each month and recommend materials for each stage.\n",
        "\n",
        "    Args:\n",
        "    inputs (dict): Dictionary containing the necessary inputs (start date, end date).\n",
        "\n",
        "    Returns:\n",
        "    list: List of dictionaries containing the predictions for each month.\n",
        "    \"\"\"\n",
        "    # Creating a data frame from the inputs\n",
        "    input_data = pd.DataFrame([inputs])\n",
        "\n",
        "    # Converting date columns to datetime objects\n",
        "    input_data['actual_commencement_date'] = pd.to_datetime(input_data['actual_commencement_date'])\n",
        "    input_data['estimated_finish_date'] = pd.to_datetime(input_data['estimated_finish_date'])\n",
        "\n",
        "    # Creating a list to store the predictions for each month\n",
        "    monthly_predictions = []\n",
        "\n",
        "    # Looping over a range of dates from the current date to the estimated finish date, with a step size of one month\n",
        "    current_date = pd.to_datetime(\"today\")\n",
        "    while current_date <= input_data['estimated_finish_date'].iloc[0]:\n",
        "        # Creating new features using the current date in the loop\n",
        "        input_data['duration_until_estimated_finish'] = (input_data['estimated_finish_date'] - input_data['actual_commencement_date']).dt.days\n",
        "        input_data['duration_since_commencement'] = (current_date - input_data['actual_commencement_date']).dt.days\n",
        "        input_data['remaining_duration'] = (input_data['estimated_finish_date'] - current_date).dt.days\n",
        "        input_data['progress_ratio'] = input_data['duration_since_commencement'] / input_data['duration_until_estimated_finish']\n",
        "        input_data['year_of_commencement'] = input_data['actual_commencement_date'].dt.year\n",
        "        input_data['month_of_commencement'] = input_data['actual_commencement_date'].dt.month\n",
        "        input_data['year_of_estimated_finish'] = input_data['estimated_finish_date'].dt.year\n",
        "        input_data['month_of_estimated_finish'] = input_data['estimated_finish_date'].dt.month\n",
        "        input_data['days_exceeding_estimated_duration'] = input_data['duration_since_commencement'] - input_data['duration_until_estimated_finish']\n",
        "        input_data['is_delayed'] = (input_data['remaining_duration'] < 0).astype(int)\n",
        "\n",
        "        # Selecting the relevant features\n",
        "        input_features = input_data[feature_columns]\n",
        "\n",
        "        # Making the prediction using the trained model to get the probability of each stage\n",
        "        predicted_probs = gbm_model.predict_proba(input_features)[0]\n",
        "\n",
        "        # Getting the most likely stage and the recommended materials for the current date in the loop\n",
        "        top_prediction_index = np.argmax(predicted_probs)\n",
        "        top_stage = label_to_stage_mapping[top_prediction_index]\n",
        "        top_probability = predicted_probs[top_prediction_index]\n",
        "        recommended_materials = materials_data.loc[materials_data['Activity'].str.contains(top_stage, case=False, na=False), 'Materials (suggestions)']\n",
        "        recommended_materials = recommended_materials.values[0] if not recommended_materials.empty else \"No materials suggested\"\n",
        "\n",
        "        # Adding the prediction for the current date to the list of monthly predictions\n",
        "        monthly_predictions.append({\n",
        "            \"Date\": current_date.strftime('%Y-%m-%d'),\n",
        "            \"Stage\": top_stage,\n",
        "            \"Probability\": top_probability,\n",
        "            \"Recommended Materials\": recommended_materials\n",
        "        })\n",
        "\n",
        "        # Moving to the next month\n",
        "        current_date = current_date + MonthEnd(1)\n",
        "\n",
        "    # Returning the results\n",
        "    return monthly_predictions\n",
        "\n",
        "# Testing the prediction function with a sample input\n",
        "test_input = {\n",
        "    \"actual_commencement_date\": \"\t2023-9-19\",\n",
        "    \"estimated_finish_date\": \"2028-02-03\",\n",
        "}\n",
        "\n",
        "predict_current_stage(test_input)\n",
        "# Export the pipeline to a PMML file\n",
        "sklearn2pmml(pipeline, \"gbm_model.pmml\", with_repr=True)\n"
      ],
      "metadata": {
        "id": "USzkBMQRuW9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn2pmml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkhEug55Pw5Q",
        "outputId": "defaff33-1bd2-43ed-d6c4-b5444be215f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn2pmml in /usr/local/lib/python3.10/dist-packages (0.98.1)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from sklearn2pmml) (0.3.7)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from sklearn2pmml) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from sklearn2pmml) (1.2.2)\n",
            "Requirement already satisfied: sklearn-pandas>=0.0.10 in /usr/local/lib/python3.10/dist-packages (from sklearn2pmml) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->sklearn2pmml) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->sklearn2pmml) (1.11.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->sklearn2pmml) (3.2.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from sklearn-pandas>=0.0.10->sklearn2pmml) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn2pmml import sklearn2pmml, PMMLPipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Define the file path to the dataset\n",
        "file_path = '/content/4th_floor_with_estimated_durations_final_output.csv'\n",
        "\n",
        "# Re-loading the dataset\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "# Converting date columns to datetime objects\n",
        "data['actual_commencement_date'] = pd.to_datetime(data['actual_commencement_date'], errors='coerce')\n",
        "data['estimated_finish_date'] = pd.to_datetime(data['estimated_finish_date'], errors='coerce')\n",
        "\n",
        "# Creating new features based on the date columns\n",
        "current_date = datetime.now()\n",
        "data['duration_until_estimated_finish'] = (data['estimated_finish_date'] - data['actual_commencement_date']).dt.days\n",
        "data['duration_since_commencement'] = (current_date - data['actual_commencement_date']).dt.days\n",
        "data['remaining_duration'] = (data['estimated_finish_date'] - current_date).dt.days\n",
        "data['progress_ratio'] = data['duration_since_commencement'] / data['duration_until_estimated_finish']\n",
        "\n",
        "# Handling missing values in the 'current_stage' column\n",
        "data.loc[(data['current_stage'].isna()) & (data['Project_status'] == 'Completed'), 'current_stage'] = 'Handover'\n",
        "\n",
        "# Step 3: Feature Engineering\n",
        "# Creating new features\n",
        "data['year_of_commencement'] = data['actual_commencement_date'].dt.year\n",
        "data['month_of_commencement'] = data['actual_commencement_date'].dt.month\n",
        "data['year_of_estimated_finish'] = data['estimated_finish_date'].dt.year\n",
        "data['month_of_estimated_finish'] = data['estimated_finish_date'].dt.month\n",
        "data['days_exceeding_estimated_duration'] = data['duration_since_commencement'] - data['duration_until_estimated_finish']\n",
        "data['is_delayed'] = (data['remaining_duration'] < 0).astype(int)\n",
        "\n",
        "# Handling other missing values with appropriate strategies\n",
        "data.fillna(data.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Performing label encoding on the 'current_stage' column\n",
        "label_encoder = LabelEncoder()\n",
        "data['current_stage'] = data['current_stage'].astype(str) # Converting to string to handle any NaN values left\n",
        "data['current_stage_encoded'] = label_encoder.fit_transform(data['current_stage'])\n",
        "\n",
        "# Step 4: Data Splitting\n",
        "# Selecting relevant features for the model\n",
        "feature_columns = [\n",
        "    'duration_until_estimated_finish', 'duration_since_commencement', 'remaining_duration',\n",
        "    'progress_ratio', 'year_of_commencement', 'month_of_commencement',\n",
        "    'year_of_estimated_finish', 'month_of_estimated_finish',\n",
        "    'days_exceeding_estimated_duration', 'is_delayed'\n",
        "]\n",
        "\n",
        "# Defining the feature set and the target variable\n",
        "X = data[feature_columns]\n",
        "y = data['current_stage_encoded']\n",
        "\n",
        "# Splitting the data into training and testing sets (80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Displaying a message to indicate the preprocessing steps are completed\n",
        "\"Data preprocessing and splitting completed successfully.\"\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initializing and training the Gradient Boosting Classifier\n",
        "gbm_model = GradientBoostingClassifier(random_state=42)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Displaying a message to indicate that the model has been trained\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Predicting the current stage on the testing set\n",
        "y_pred = gbm_model.predict(X_test)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# Getting the classification report with the correct labels\n",
        "class_report = classification_report(y_test, y_pred, labels=unique_labels, target_names=label_encoder.classes_[unique_labels])\n",
        "\n",
        "accuracy, class_report\n",
        "\n",
        "\n",
        "# Getting the classification report with the correct labels\n",
        "class_report = classification_report(y_test, y_pred, labels=unique_labels, target_names=label_encoder.classes_[unique_labels])\n",
        "\n",
        "accuracy, class_report\n",
        "# Create a PMMLPipeline with the trained model\n",
        "pipeline = PMMLPipeline([(\"classifier\", gbm_model)])\n",
        "# Export the pipeline to a PMML file\n",
        "sklearn2pmml(pipeline, \"gbm_model.pmml\", with_repr=True)\n",
        "\n",
        "# Getting the unique stage names in the main dataset and the materials data file\n",
        "import pandas as pd\n",
        "\n",
        "materials_data = pd.read_csv(\"/content/Copy of stage_with materai.csv\")\n",
        "unique_stages_main_dataset = data['current_stage'].unique()\n",
        "unique_stages_materials_data = materials_data['Activity'].unique()\n",
        "\n",
        "unique_stages_main_dataset, unique_stages_materials_data\n",
        "# Removing the \"_estimated_duration\" suffix from the stage names in the main dataset\n",
        "data['current_stage_cleaned'] = data['current_stage'].str.replace('_estimated_duration', '')\n",
        "\n",
        "# Updating the label encoder to use the cleaned stage names\n",
        "label_encoder = LabelEncoder()\n",
        "data['current_stage_encoded'] = label_encoder.fit_transform(data['current_stage_cleaned'].astype(str))\n",
        "\n",
        "# Creating a dictionary to map the encoded labels to the cleaned stage names\n",
        "label_to_stage_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
        "\n",
        "# Displaying the cleaned unique stage names\n",
        "cleaned_unique_stages_main_dataset = data['current_stage_cleaned'].unique()\n",
        "from pandas.tseries.offsets import MonthEnd\n",
        "\n",
        "# Updating the prediction function to provide predictions for the current and upcoming stages for each month\n",
        "\n",
        "# Defining the prediction function\n",
        "def predict_current_stage(inputs):\n",
        "    \"\"\"\n",
        "    Function to predict the current and upcoming stages for each month and recommend materials for each stage.\n",
        "\n",
        "    Args:\n",
        "    inputs (dict): Dictionary containing the necessary inputs (start date, end date).\n",
        "\n",
        "    Returns:\n",
        "    list: List of dictionaries containing the predictions for each month.\n",
        "    \"\"\"\n",
        "    # Creating a data frame from the inputs\n",
        "    input_data = pd.DataFrame([inputs])\n",
        "\n",
        "    # Converting date columns to datetime objects\n",
        "    input_data['actual_commencement_date'] = pd.to_datetime(input_data['actual_commencement_date'])\n",
        "    input_data['estimated_finish_date'] = pd.to_datetime(input_data['estimated_finish_date'])\n",
        "\n",
        "    # Creating a list to store the predictions for each month\n",
        "    monthly_predictions = []\n",
        "\n",
        "    # Looping over a range of dates from the current date to the estimated finish date, with a step size of one month\n",
        "    current_date = pd.to_datetime(\"today\")\n",
        "    while current_date <= input_data['estimated_finish_date'].iloc[0]:\n",
        "        # Creating new features using the current date in the loop\n",
        "        input_data['duration_until_estimated_finish'] = (input_data['estimated_finish_date'] - input_data['actual_commencement_date']).dt.days\n",
        "        input_data['duration_since_commencement'] = (current_date - input_data['actual_commencement_date']).dt.days\n",
        "        input_data['remaining_duration'] = (input_data['estimated_finish_date'] - current_date).dt.days\n",
        "        input_data['progress_ratio'] = input_data['duration_since_commencement'] / input_data['duration_until_estimated_finish']\n",
        "        input_data['year_of_commencement'] = input_data['actual_commencement_date'].dt.year\n",
        "        input_data['month_of_commencement'] = input_data['actual_commencement_date'].dt.month\n",
        "        input_data['year_of_estimated_finish'] = input_data['estimated_finish_date'].dt.year\n",
        "        input_data['month_of_estimated_finish'] = input_data['estimated_finish_date'].dt.month\n",
        "        input_data['days_exceeding_estimated_duration'] = input_data['duration_since_commencement'] - input_data['duration_until_estimated_finish']\n",
        "        input_data['is_delayed'] = (input_data['remaining_duration'] < 0).astype(int)\n",
        "\n",
        "        # Selecting the relevant features\n",
        "        input_features = input_data[feature_columns]\n",
        "\n",
        "        # Making the prediction using the trained model to get the probability of each stage\n",
        "        predicted_probs = gbm_model.predict_proba(input_features)[0]\n",
        "\n",
        "        # Getting the most likely stage and the recommended materials for the current date in the loop\n",
        "        top_prediction_index = np.argmax(predicted_probs)\n",
        "        top_stage = label_to_stage_mapping[top_prediction_index]\n",
        "        top_probability = predicted_probs[top_prediction_index]\n",
        "        recommended_materials = materials_data.loc[materials_data['Activity'].str.contains(top_stage, case=False, na=False), 'Materials (suggestions)']\n",
        "        recommended_materials = recommended_materials.values[0] if not recommended_materials.empty else \"No materials suggested\"\n",
        "\n",
        "        # Adding the prediction for the current date to the list of monthly predictions\n",
        "        monthly_predictions.append({\n",
        "            \"Date\": current_date.strftime('%Y-%m-%d'),\n",
        "            \"Stage\": top_stage,\n",
        "            \"Probability\": top_probability,\n",
        "            \"Recommended Materials\": recommended_materials\n",
        "        })\n",
        "\n",
        "        # Moving to the next month\n",
        "        current_date = current_date + MonthEnd(1)\n",
        "\n",
        "    # Returning the results\n",
        "    return monthly_predictions\n",
        "\n",
        "# Testing the prediction function with a sample input\n",
        "test_input = {\n",
        "    \"actual_commencement_date\": \"\t2023-9-19\",\n",
        "    \"estimated_finish_date\": \"2028-02-03\",\n",
        "}\n",
        "\n",
        "predict_current_stage(test_input)\n",
        "# Export the pipeline to a PMML file\n",
        "sklearn2pmml(pipeline, \"gbm_model.pmml\", with_repr=True)\n"
      ],
      "metadata": {
        "id": "Xc2SoqsIPsXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}