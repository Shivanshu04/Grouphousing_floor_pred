{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d627ea05-a03f-4290-915f-5b2d1aaa6291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.session import s3_input, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c177533b-11d4-40cc-8763-b31486df29ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating bucket: An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_s3_bucket(bucket_name, region=\"ap-south-1\"):\n",
    "    s3 = boto3.client('s3', region_name=region)\n",
    "    \n",
    "    try:\n",
    "        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "        print(f\"Bucket {bucket_name} created successfully in {region} region!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bucket: {e}\")\n",
    "\n",
    "# Usage:\n",
    "bucket_name = \"demomlbucket202\"  # Bucket names must be globally unique\n",
    "create_s3_bucket(bucket_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0deedab-4342-4b33-a72e-889c0ad227b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 4th_floor_with_estimated_durations_final_output.csv uploaded successfully to demomlbucket202/desired/data.csv!\n"
     ]
    }
   ],
   "source": [
    "# Function to upload a file to the specified S3 bucket\n",
    "def upload_file_to_s3(bucket_name, local_file_path, s3_file_key):\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        s3.upload_file(local_file_path, bucket_name, s3_file_key)\n",
    "        print(f\"File {local_file_path} uploaded successfully to {bucket_name}/{s3_file_key}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "# Upload a file to the created bucket\n",
    "local_file_path = \"4th_floor_with_estimated_durations_final_output.csv\"\n",
    "s3_file_key = \"desired/data.csv\"\n",
    "upload_file_to_s3(bucket_name, local_file_path, s3_file_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbc58431-a299-4c6a-abb7-6bf88d4cb403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_data(data):\n",
    "    try:\n",
    "        # Convert date columns to datetime objects\n",
    "        data['actual_commencement_date'] = pd.to_datetime(data['actual_commencement_date'], errors='coerce')\n",
    "        data['estimated_finish_date'] = pd.to_datetime(data['estimated_finish_date'], errors='coerce')\n",
    "\n",
    "        # Create new date-based features\n",
    "        current_date = datetime.now()\n",
    "        data['duration_until_estimated_finish'] = (data['estimated_finish_date'] - data['actual_commencement_date']).dt.days\n",
    "        data['duration_since_commencement'] = (current_date - data['actual_commencement_date']).dt.days\n",
    "        data['remaining_duration'] = (data['estimated_finish_date'] - current_date).dt.days\n",
    "        data['progress_ratio'] = data['duration_since_commencement'] / data['duration_until_estimated_finish']\n",
    "\n",
    "        # Handle missing values\n",
    "        data.loc[(data['current_stage'].isna()) & (data['Project_status'] == 'Completed'), 'current_stage'] = 'Handover'\n",
    "        \n",
    "        # Further feature engineering\n",
    "        data['year_of_commencement'] = data['actual_commencement_date'].dt.year\n",
    "        data['month_of_commencement'] = data['actual_commencement_date'].dt.month\n",
    "        data['year_of_estimated_finish'] = data['estimated_finish_date'].dt.year\n",
    "        data['month_of_estimated_finish'] = data['estimated_finish_date'].dt.month\n",
    "        data['days_exceeding_estimated_duration'] = data['duration_since_commencement'] - data['duration_until_estimated_finish']\n",
    "        data['is_delayed'] = (data['remaining_duration'] < 0).astype(int)\n",
    "\n",
    "        # Handle other missing values\n",
    "        data.fillna(data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "def encode_data(data):\n",
    "    try:\n",
    "        # Label Encoding\n",
    "        label_encoder = LabelEncoder()\n",
    "        data['current_stage'] = data['current_stage'].astype(str) # To handle any NaN values left\n",
    "        data['current_stage_encoded'] = label_encoder.fit_transform(data['current_stage'])\n",
    "\n",
    "        # OneHot Encoding (Optional based on the number of unique values in 'current_stage')\n",
    "        if len(data['current_stage'].unique()) > 10: # This threshold can be adjusted\n",
    "            onehot_encoder = OneHotEncoder()\n",
    "            encoded_features = onehot_encoder.fit_transform(data[['current_stage']])\n",
    "            data = pd.concat([data, pd.DataFrame(encoded_features.toarray(), columns=onehot_encoder.get_feature_names(['current_stage']))], axis=1)\n",
    "\n",
    "        return data, label_encoder\n",
    "    except Exception as e:\n",
    "        print(f\"Error in encoding: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def split_data(data):\n",
    "    # Define relevant features for the model\n",
    "    feature_columns = [\n",
    "        'duration_until_estimated_finish', 'duration_since_commencement', 'remaining_duration',\n",
    "        'progress_ratio', 'year_of_commencement', 'month_of_commencement',\n",
    "        'year_of_estimated_finish', 'month_of_estimated_finish',\n",
    "        'days_exceeding_estimated_duration', 'is_delayed'\n",
    "    ]\n",
    "    X = data[feature_columns]\n",
    "    y = data['current_stage_encoded']\n",
    "\n",
    "    # Split the data\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Usage:\n",
    "\n",
    "file_path = '4th_floor_with_estimated_durations_final_output.csv'\n",
    "data = load_data(file_path)\n",
    "if data is not None:\n",
    "    data = preprocess_data(data)\n",
    "    if data is not None:\n",
    "        data, label_encoder = encode_data(data)\n",
    "        if data is not None and label_encoder is not None:\n",
    "            X_train, X_test, y_train, y_test = split_data(data)\n",
    "            print(\"Data processing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d45e34e7-f1f5-4ccf-af58-43ced881d277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gradient Boosting Model has been trained successfully.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initializing and training the Gradient Boosting Classifier\n",
    "gbm_model = GradientBoostingClassifier(random_state=42)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Displaying a message to indicate that the model has been trained\n",
    "\"Gradient Boosting Model has been trained successfully.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42acefa6-7407-4c92-8047-3f85a6f231da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.950207468879668\n",
      "\n",
      "Classification Report:\n",
      "                                                                                              precision    recall  f1-score   support\n",
      "\n",
      "                                                  1st Floor slab casting_estimated_duration       1.00      0.67      0.80         3\n",
      "                                               1st floor Columns casting_estimated_duration       0.50      0.50      0.50         2\n",
      "                                                  2nd Floor slab casting_estimated_duration       1.00      0.88      0.93         8\n",
      "                                                  3rd Floor slab casting_estimated_duration       1.00      1.00      1.00         7\n",
      "                                              3rd floor Columns casting _estimated_duration       0.50      1.00      0.67         1\n",
      "                                                  4th Floor slab casting_estimated_duration       1.00      1.00      1.00         5\n",
      "                                              4th floor Columns casting _estimated_duration       1.00      1.00      1.00         3\n",
      "                                                Brick work at 1st Floor _estimated_duration       1.00      1.00      1.00         2\n",
      "                                 Brick work at Basement to Ground Floor _estimated_duration       0.86      1.00      0.92         6\n",
      "                                         Brick work of 2nd to 4th Floor _estimated_duration       1.00      1.00      1.00         6\n",
      "                                                       Cleaning & survey_estimated_duration       1.00      1.00      1.00        38\n",
      "                                   Doors & Windows Fixing Furniture work_estimated_duration       0.95      1.00      0.98        21\n",
      "          Electrical concealed, PVC Fitting, plastering at 1st-4th floor_estimated_duration       1.00      1.00      1.00         9\n",
      "               Electrical concealed, PVC Fitting, plastering at Basement_estimated_duration       1.00      0.50      0.67         2\n",
      "           Electrical concealed, PVC Fitting, plastering at ground floor_estimated_duration       1.00      1.00      1.00         6\n",
      "                          Excavation,leveling & P.C.C  for Basement  B1 _estimated_duration       0.89      1.00      0.94         8\n",
      "                                              Ground Floor slab casting _estimated_duration       0.50      1.00      0.67         2\n",
      "                                                                                   Handover       0.96      1.00      0.98        53\n",
      "                                                  Painting and Finishing_estimated_duration       0.94      0.83      0.88        18\n",
      "                                               Plastering on outer sides_estimated_duration       1.00      1.00      1.00         9\n",
      "                               Plumbing & Sanitary,Electrification Works_estimated_duration       0.83      0.83      0.83        12\n",
      "Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring _estimated_duration       1.00      0.67      0.80         3\n",
      "                                                     Slab of B (bottom) _estimated_duration       1.00      0.75      0.86         4\n",
      "                                                              Tiles work_estimated_duration       1.00      0.92      0.96        13\n",
      "\n",
      "                                                                                   accuracy                           0.95       241\n",
      "                                                                                  macro avg       0.91      0.90      0.89       241\n",
      "                                                                               weighted avg       0.96      0.95      0.95       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label_encoder):\n",
    "    try:\n",
    "        # Predicting the current stage on the testing set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculating the accuracy of the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Getting the unique labels present in the test set and predictions\n",
    "        unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "        \n",
    "        # Getting the classification report with the correct labels\n",
    "        class_report = classification_report(y_test, y_pred, labels=unique_labels, target_names=label_encoder.classes_[unique_labels])\n",
    "        \n",
    "        return accuracy, class_report\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Usage:\n",
    "\n",
    "accuracy, class_report = evaluate_model(gbm_model, X_test, y_test, label_encoder)\n",
    "\n",
    "if accuracy is not None and class_report is not None:\n",
    "    print(\"Model Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7f8169d-4be2-4b8e-b2fb-dcd294b2c402",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Copy of stage_with materai.csv uploaded successfully to demomlbucket202/desired/stages.csv!\n"
     ]
    }
   ],
   "source": [
    "# Function to upload a file to the specified S3 bucket\n",
    "def upload_file_to_s3(bucket_name, local_file_path, s3_file_key):\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        s3.upload_file(local_file_path, bucket_name, s3_file_key)\n",
    "        print(f\"File {local_file_path} uploaded successfully to {bucket_name}/{s3_file_key}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "# Upload a file to the created bucket\n",
    "local_file_path = \"Copy of stage_with materai.csv\"\n",
    "s3_file_key = \"desired/stages.csv\"\n",
    "upload_file_to_s3(bucket_name, local_file_path, s3_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0387a020-ddde-4c19-95d2-c3b7560914db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Handover',\n",
       "        'Plumbing & Sanitary,Electrification Works_estimated_duration',\n",
       "        'Plastering on outer sides_estimated_duration',\n",
       "        'Painting and Finishing_estimated_duration',\n",
       "        '3rd Floor slab casting_estimated_duration',\n",
       "        'Electrical concealed, PVC Fitting, plastering at 1st-4th floor_estimated_duration',\n",
       "        'nan', 'Brick work at 1st Floor _estimated_duration',\n",
       "        '3rd floor Columns casting _estimated_duration',\n",
       "        'Tiles work_estimated_duration',\n",
       "        'Electrical concealed, PVC Fitting, plastering at ground floor_estimated_duration',\n",
       "        '4th Floor slab casting_estimated_duration',\n",
       "        'Brick work of 2nd to 4th Floor _estimated_duration',\n",
       "        'Doors & Windows Fixing Furniture work_estimated_duration',\n",
       "        'Ground Floor slab casting _estimated_duration',\n",
       "        'Cleaning & survey_estimated_duration',\n",
       "        '1st Floor slab casting_estimated_duration',\n",
       "        'Excavation,leveling & P.C.C  for Basement  B1 _estimated_duration',\n",
       "        '4th floor Columns casting _estimated_duration',\n",
       "        'Brick work at Basement to Ground Floor _estimated_duration',\n",
       "        'Slab of B (bottom) _estimated_duration',\n",
       "        'Electrical concealed, PVC Fitting, plastering at Basement_estimated_duration',\n",
       "        '2nd floor Columns casting _estimated_duration',\n",
       "        '2nd Floor slab casting_estimated_duration',\n",
       "        'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring _estimated_duration',\n",
       "        '1st floor Columns casting_estimated_duration'], dtype=object),\n",
       " array(['Cleaning & survey',\n",
       "        'Excavation,leveling & P.C.C  for Basement  B1 ',\n",
       "        ' Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring ',\n",
       "        'Slab of B (bottom) ', ' Ground Floor slab casting ',\n",
       "        ' 1st floor Columns casting', ' 1st Floor slab casting',\n",
       "        '2nd floor Columns casting ', '2nd Floor slab casting',\n",
       "        ' Brick work at Basement to Ground Floor ',\n",
       "        'Electrical concealed, PVC Fitting, plastering at Basement',\n",
       "        '3rd floor Columns casting ', '3rd Floor slab casting',\n",
       "        ' Brick work at 1st Floor ',\n",
       "        'Electrical concealed, PVC Fitting, plastering at ground floor',\n",
       "        '4th floor Columns casting ', '4th Floor slab casting',\n",
       "        ' Brick work of 2nd to 4th Floor ',\n",
       "        'Electrical concealed, PVC Fitting, plastering at 1st-4th floor',\n",
       "        'Plastering on outer sides', 'Tiles work',\n",
       "        'Painting and Finishing',\n",
       "        'Plumbing & Sanitary,Electrification Works',\n",
       "        'Doors & Windows Fixing Furniture work'], dtype=object))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the unique stage names in the main dataset and the materials data file\n",
    "import pandas as pd\n",
    "\n",
    "materials_data = pd.read_csv(\"Copy of stage_with materai.csv\")\n",
    "unique_stages_main_dataset = data['current_stage'].unique()\n",
    "unique_stages_materials_data = materials_data['Activity'].unique()\n",
    "\n",
    "unique_stages_main_dataset, unique_stages_materials_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a6ebada-334c-48cc-af98-df32a87f6f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Handover', 'Plumbing & Sanitary,Electrification Works',\n",
       "       'Plastering on outer sides', 'Painting and Finishing',\n",
       "       '3rd Floor slab casting',\n",
       "       'Electrical concealed, PVC Fitting, plastering at 1st-4th floor',\n",
       "       'nan', 'Brick work at 1st Floor ', '3rd floor Columns casting ',\n",
       "       'Tiles work',\n",
       "       'Electrical concealed, PVC Fitting, plastering at ground floor',\n",
       "       '4th Floor slab casting', 'Brick work of 2nd to 4th Floor ',\n",
       "       'Doors & Windows Fixing Furniture work',\n",
       "       'Ground Floor slab casting ', 'Cleaning & survey',\n",
       "       '1st Floor slab casting',\n",
       "       'Excavation,leveling & P.C.C  for Basement  B1 ',\n",
       "       '4th floor Columns casting ',\n",
       "       'Brick work at Basement to Ground Floor ', 'Slab of B (bottom) ',\n",
       "       'Electrical concealed, PVC Fitting, plastering at Basement',\n",
       "       '2nd floor Columns casting ', '2nd Floor slab casting',\n",
       "       'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring ',\n",
       "       '1st floor Columns casting'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the \"_estimated_duration\" suffix from the stage names in the main dataset\n",
    "data['current_stage_cleaned'] = data['current_stage'].str.replace('_estimated_duration', '')\n",
    "\n",
    "# Updating the label encoder to use the cleaned stage names\n",
    "label_encoder = LabelEncoder()\n",
    "data['current_stage_encoded'] = label_encoder.fit_transform(data['current_stage_cleaned'].astype(str))\n",
    "\n",
    "# Creating a dictionary to map the encoded labels to the cleaned stage names\n",
    "label_to_stage_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "\n",
    "# Displaying the cleaned unique stage names\n",
    "cleaned_unique_stages_main_dataset = data['current_stage_cleaned'].unique()\n",
    "cleaned_unique_stages_main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fd01e16-15be-42e2-bda9-fc077c1627c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Handover', 'Plumbing & Sanitary,Electrification Works',\n",
       "       'Plastering on outer sides', 'Painting and Finishing',\n",
       "       '3rd Floor slab casting',\n",
       "       'Electrical concealed, PVC Fitting, plastering at 1st-4th floor',\n",
       "       'nan', 'Brick work at 1st Floor ', '3rd floor Columns casting ',\n",
       "       'Tiles work',\n",
       "       'Electrical concealed, PVC Fitting, plastering at ground floor',\n",
       "       '4th Floor slab casting', 'Brick work of 2nd to 4th Floor ',\n",
       "       'Doors & Windows Fixing Furniture work',\n",
       "       'Ground Floor slab casting ', 'Cleaning & survey',\n",
       "       '1st Floor slab casting',\n",
       "       'Excavation,leveling & P.C.C  for Basement  B1 ',\n",
       "       '4th floor Columns casting ',\n",
       "       'Brick work at Basement to Ground Floor ', 'Slab of B (bottom) ',\n",
       "       'Electrical concealed, PVC Fitting, plastering at Basement',\n",
       "       '2nd floor Columns casting ', '2nd Floor slab casting',\n",
       "       'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring ',\n",
       "       '1st floor Columns casting'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the \"_estimated_duration\" suffix from the stage names in the main dataset\n",
    "data['current_stage_cleaned'] = data['current_stage'].str.replace('_estimated_duration', '')\n",
    "\n",
    "# Updating the label encoder to use the cleaned stage names\n",
    "label_encoder = LabelEncoder()\n",
    "data['current_stage_encoded'] = label_encoder.fit_transform(data['current_stage_cleaned'].astype(str))\n",
    "\n",
    "# Creating a dictionary to map the encoded labels to the cleaned stage names\n",
    "label_to_stage_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "\n",
    "# Displaying the cleaned unique stage names\n",
    "cleaned_unique_stages_main_dataset = data['current_stage_cleaned'].unique()\n",
    "cleaned_unique_stages_main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b655994-a148-4b7c-a0ff-e1db4e9414b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Updating the prediction function to use the cleaned stage names\n",
    "\n",
    "# Defining the prediction function\n",
    "def predict_current_stage(inputs):\n",
    "    \"\"\"\n",
    "    Function to predict the current stage of a project and recommend materials.\n",
    "\n",
    "    Args:\n",
    "    inputs (dict): Dictionary containing the necessary inputs (start date, end date).\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing the predicted stage and recommended materials.\n",
    "    \"\"\"\n",
    "    # Creating a data frame from the inputs\n",
    "    input_data = pd.DataFrame([inputs])\n",
    "\n",
    "    # Converting date columns to datetime objects and creating new features\n",
    "    input_data['actual_commencement_date'] = pd.to_datetime(input_data['actual_commencement_date'])\n",
    "    input_data['estimated_finish_date'] = pd.to_datetime(input_data['estimated_finish_date'])\n",
    "    current_date = datetime.now()\n",
    "    input_data['duration_until_estimated_finish'] = (input_data['estimated_finish_date'] - input_data['actual_commencement_date']).dt.days\n",
    "    input_data['duration_since_commencement'] = (current_date - input_data['actual_commencement_date']).dt.days\n",
    "    input_data['remaining_duration'] = (input_data['estimated_finish_date'] - current_date).dt.days\n",
    "    input_data['progress_ratio'] = input_data['duration_since_commencement'] / input_data['duration_until_estimated_finish']\n",
    "    input_data['year_of_commencement'] = input_data['actual_commencement_date'].dt.year\n",
    "    input_data['month_of_commencement'] = input_data['actual_commencement_date'].dt.month\n",
    "    input_data['year_of_estimated_finish'] = input_data['estimated_finish_date'].dt.year\n",
    "    input_data['month_of_estimated_finish'] = input_data['estimated_finish_date'].dt.month\n",
    "    input_data['days_exceeding_estimated_duration'] = input_data['duration_since_commencement'] - input_data['duration_until_estimated_finish']\n",
    "    input_data['is_delayed'] = (input_data['remaining_duration'] < 0).astype(int)\n",
    "\n",
    "    # Selecting the relevant features\n",
    "    input_features = input_data[feature_columns]\n",
    "\n",
    "    # Making the prediction using the trained model\n",
    "    predicted_label = gbm_model.predict(input_features)[0]\n",
    "\n",
    "    # Getting the predicted stage and the recommended materials\n",
    "    predicted_stage = label_to_stage_mapping[predicted_label]\n",
    "    recommended_materials = materials_data.loc[materials_data['Activity'].str.contains(predicted_stage, case=False, na=False), 'Materials (suggestions)'].values[0]\n",
    "\n",
    "    # Returning the results\n",
    "    return {\n",
    "        \"Predicted Stage\": predicted_stage,\n",
    "        \"Recommended Materials\": recommended_materials\n",
    "    }\n",
    "\n",
    "# Testing the prediction function with a sample input\n",
    "test_input = {\n",
    "    \"actual_commencement_date\": \"2022-03-22\",\n",
    "    \"estimated_finish_date\": \"2024-12-31\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f7924a4-2a4e-401f-924d-cb3360d68850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "def predict_current_stage(inputs, feature_columns):\n",
    "    try:\n",
    "        # Creating a data frame from the inputs\n",
    "        input_data = pd.DataFrame([inputs])\n",
    "\n",
    "        # Check if necessary columns are present\n",
    "        for column in ['actual_commencement_date', 'estimated_finish_date']:\n",
    "            if column not in input_data.columns:\n",
    "                raise ValueError(f\"Input is missing the {column} column.\")\n",
    "\n",
    "        # Convert date columns to datetime objects and create new features\n",
    "        input_data['actual_commencement_date'] = pd.to_datetime(input_data['actual_commencement_date'])\n",
    "        input_data['estimated_finish_date'] = pd.to_datetime(input_data['estimated_finish_date'])\n",
    "        current_date = datetime.now()\n",
    "        input_data['duration_until_estimated_finish'] = (input_data['estimated_finish_date'] - input_data['actual_commencement_date']).dt.days\n",
    "        input_data['duration_since_commencement'] = (current_date - input_data['actual_commencement_date']).dt.days\n",
    "        input_data['remaining_duration'] = (input_data['estimated_finish_date'] - current_date).dt.days\n",
    "        input_data['progress_ratio'] = input_data['duration_since_commencement'] / input_data['duration_until_estimated_finish']\n",
    "        input_data['year_of_commencement'] = input_data['actual_commencement_date'].dt.year\n",
    "        input_data['month_of_commencement'] = input_data['actual_commencement_date'].dt.month\n",
    "        input_data['year_of_estimated_finish'] = input_data['estimated_finish_date'].dt.year\n",
    "        input_data['month_of_estimated_finish'] = input_data['estimated_finish_date'].dt.month\n",
    "        input_data['days_exceeding_estimated_duration'] = input_data['duration_since_commencement'] - input_data['duration_until_estimated_finish']\n",
    "        input_data['is_delayed'] = (input_data['remaining_duration'] < 0).astype(int)\n",
    "\n",
    "        # Select the relevant features\n",
    "        input_features = input_data[feature_columns]\n",
    "\n",
    "        # Make the prediction using the trained model to get the probability of each stage\n",
    "        predicted_probs = gbm_model.predict_proba(input_features)[0]\n",
    "\n",
    "        # Get all possible stages and the recommended materials for each stage, ordered by probability\n",
    "        predictions = []\n",
    "        for i, prob in enumerate(predicted_probs):\n",
    "            stage = label_to_stage_mapping.get(i, \"Unknown Stage\")\n",
    "            recommended_materials = materials_data.loc[materials_data['Activity'].str.contains(stage, case=False, na=False), 'Materials (suggestions)']\n",
    "            recommended_materials = recommended_materials.values[0] if not recommended_materials.empty else \"No materials suggested\"\n",
    "            predictions.append({\n",
    "                \"Stage\": stage,\n",
    "                \"Probability\": prob,\n",
    "                \"Recommended Materials\": recommended_materials\n",
    "            })\n",
    "\n",
    "        # Sort the predictions by probability in descending order\n",
    "        predictions = sorted(predictions, key=lambda x: x['Probability'], reverse=True)\n",
    "\n",
    "        # Return the results\n",
    "        return predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting current stage: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33c194a1-ccaf-498c-aec8-799b4415025a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'duration_until_estimated_finish', 'duration_since_commencement', 'remaining_duration',\n",
    "    'progress_ratio', 'year_of_commencement', 'month_of_commencement',\n",
    "    'year_of_estimated_finish', 'month_of_estimated_finish',\n",
    "    'days_exceeding_estimated_duration', 'is_delayed'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6896f7d-9578-4265-ab96-ef0de658da03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Stage': 'Tiles work', 'Probability': 0.7562216961378654, 'Recommended Materials': 'Tiles'}, {'Stage': 'Painting and Finishing', 'Probability': 0.24309785840189183, 'Recommended Materials': 'paint, putty,primer'}, {'Stage': 'Plastering on outer sides', 'Probability': 0.00034507960045352233, 'Recommended Materials': 'cement, sand'}, {'Stage': 'Handover', 'Probability': 5.3713738533198076e-05, 'Recommended Materials': 'No materials suggested'}, {'Stage': 'Electrical concealed, PVC Fitting, plastering at ground floor', 'Probability': 4.9627991661802246e-05, 'Recommended Materials': 'cement, sand,  circuit pipe, Cpvc,&Pvc pipe'}, {'Stage': 'Cleaning & survey', 'Probability': 3.6924559934658875e-05, 'Recommended Materials': nan}, {'Stage': '3rd Floor slab casting', 'Probability': 3.123673008364434e-05, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates'}, {'Stage': '4th Floor slab casting', 'Probability': 2.7388978265419757e-05, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates,Pvc pipes,circuit pipes,lightbox, fan box'}, {'Stage': 'Doors & Windows Fixing Furniture work', 'Probability': 1.6905467660814908e-05, 'Recommended Materials': 'Furniture, hardware, glass'}, {'Stage': 'Electrical concealed, PVC Fitting, plastering at 1st-4th floor', 'Probability': 1.5437482302358636e-05, 'Recommended Materials': 'cement, sand,  circuit pipe, Cpvc,&Pvc pipe'}, {'Stage': 'Brick work at 1st Floor ', 'Probability': 1.4765938630328534e-05, 'Recommended Materials': ' blocks/bricks'}, {'Stage': 'Plumbing & Sanitary,Electrification Works', 'Probability': 1.2559542179743623e-05, 'Recommended Materials': 'Wire, switch, nozzle Bib cock, shower, kitchen accessories, lights, fans, sheets, basin, sink, etc.'}, {'Stage': '3rd floor Columns casting ', 'Probability': 1.0315967745026864e-05, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates,Pvc pipes,circuit pipes,lightbox, fan box'}, {'Stage': 'Brick work of 2nd to 4th Floor ', 'Probability': 8.347325191309881e-06, 'Recommended Materials': ' blocks/bricks'}, {'Stage': 'Brick work at Basement to Ground Floor ', 'Probability': 8.209486215745846e-06, 'Recommended Materials': ' blocks/bricks'}, {'Stage': 'Excavation,leveling & P.C.C  for Basement  B1 ', 'Probability': 8.060516676312839e-06, 'Recommended Materials': 'cement, sand, aggregates'}, {'Stage': '2nd Floor slab casting', 'Probability': 7.1824887177325385e-06, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates,Pvc pipes,circuit pipes,lightbox, fan box'}, {'Stage': 'Electrical concealed, PVC Fitting, plastering at Basement', 'Probability': 6.9161287912534616e-06, 'Recommended Materials': 'cement, sand, circuit pipe, Cpvc,&Pvc pipe'}, {'Stage': 'Ground Floor slab casting ', 'Probability': 5.7086160019547635e-06, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates ,Pvc pipes,circuit pipes,lightbox, fan box'}, {'Stage': '1st Floor slab casting', 'Probability': 5.708232254480358e-06, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates ,Pvc pipes,circuit pipes,lightbox, fan box'}, {'Stage': '4th floor Columns casting ', 'Probability': 4.311438034953197e-06, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates '}, {'Stage': 'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring ', 'Probability': 4.220180956000459e-06, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates'}, {'Stage': 'Slab of B (bottom) ', 'Probability': 3.0307272046827133e-06, 'Recommended Materials': 'No materials suggested'}, {'Stage': '2nd floor Columns casting ', 'Probability': 3.024215413507546e-06, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates'}, {'Stage': '1st floor Columns casting', 'Probability': 1.4653903998919306e-06, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates'}, {'Stage': 'nan', 'Probability': 3.047169344792995e-07, 'Recommended Materials': 'No materials suggested'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151/2415191367.py:38: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  recommended_materials = materials_data.loc[materials_data['Activity'].str.contains(stage, case=False, na=False), 'Materials (suggestions)']\n"
     ]
    }
   ],
   "source": [
    "test_input = {\n",
    "    \"actual_commencement_date\": \"2023-01-01\",\n",
    "    \"estimated_finish_date\": \"2023-12-31\",\n",
    "}\n",
    "\n",
    "results = predict_current_stage(test_input, feature_columns)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3af30b18-2051-41df-94bf-6960306b4111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Date': '2023-09-27', 'Stage': 'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring ', 'Probability': 0.9999997952300529, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates'}, {'Date': '2023-09-30', 'Stage': 'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring ', 'Probability': 0.9999997910600721, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates'}, {'Date': '2023-10-31', 'Stage': 'Ground Floor slab casting ', 'Probability': 0.9999986250059786, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates ,Pvc pipes,circuit pipes,lightbox, fan box'}, {'Date': '2023-11-30', 'Stage': '2nd floor Columns casting ', 'Probability': 0.9999998738109648, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates'}, {'Date': '2023-12-31', 'Stage': 'Brick work at Basement to Ground Floor ', 'Probability': 0.9999993383237755, 'Recommended Materials': ' blocks/bricks'}, {'Date': '2024-01-31', 'Stage': '3rd Floor slab casting', 'Probability': 0.999997481828231, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates'}, {'Date': '2024-02-29', 'Stage': '4th floor Columns casting ', 'Probability': 0.997221590181355, 'Recommended Materials': 'TMT bar ,cement, sand, aggregates '}, {'Date': '2024-03-31', 'Stage': 'Brick work of 2nd to 4th Floor ', 'Probability': 0.9999997466471273, 'Recommended Materials': ' blocks/bricks'}, {'Date': '2024-04-30', 'Stage': 'Electrical concealed, PVC Fitting, plastering at 1st-4th floor', 'Probability': 0.999999546640854, 'Recommended Materials': 'cement, sand,  circuit pipe, Cpvc,&Pvc pipe'}, {'Date': '2024-05-31', 'Stage': 'Plastering on outer sides', 'Probability': 0.9999580741671, 'Recommended Materials': 'cement, sand'}, {'Date': '2024-06-30', 'Stage': 'Tiles work', 'Probability': 0.9999134279609592, 'Recommended Materials': 'Tiles'}, {'Date': '2024-07-31', 'Stage': 'Tiles work', 'Probability': 0.9964381403309742, 'Recommended Materials': 'Tiles'}, {'Date': '2024-08-31', 'Stage': 'Painting and Finishing', 'Probability': 0.9999961877296913, 'Recommended Materials': 'paint, putty,primer'}, {'Date': '2024-09-30', 'Stage': 'Plumbing & Sanitary,Electrification Works', 'Probability': 0.9999986450583136, 'Recommended Materials': 'Wire, switch, nozzle Bib cock, shower, kitchen accessories, lights, fans, sheets, basin, sink, etc.'}, {'Date': '2024-10-31', 'Stage': 'Doors & Windows Fixing Furniture work', 'Probability': 0.999964078055996, 'Recommended Materials': 'Furniture, hardware, glass'}, {'Date': '2024-11-30', 'Stage': 'Doors & Windows Fixing Furniture work', 'Probability': 0.999964078055996, 'Recommended Materials': 'Furniture, hardware, glass'}]\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.offsets import MonthEnd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def predict_current_stage(inputs, feature_columns, gbm_model, label_to_stage_mapping, materials_data):\n",
    "    try:\n",
    "        # Creating a dataframe from the inputs\n",
    "        input_data = pd.DataFrame([inputs])\n",
    "\n",
    "        # Convert date columns to datetime objects\n",
    "        input_data['actual_commencement_date'] = pd.to_datetime(input_data['actual_commencement_date'])\n",
    "        input_data['estimated_finish_date'] = pd.to_datetime(input_data['estimated_finish_date'])\n",
    "\n",
    "        # Initialize features that do not change within the loop\n",
    "        input_data['duration_until_estimated_finish'] = (input_data['estimated_finish_date'] - input_data['actual_commencement_date']).dt.days\n",
    "        input_data['year_of_commencement'] = input_data['actual_commencement_date'].dt.year\n",
    "        input_data['month_of_commencement'] = input_data['actual_commencement_date'].dt.month\n",
    "        input_data['year_of_estimated_finish'] = input_data['estimated_finish_date'].dt.year\n",
    "        input_data['month_of_estimated_finish'] = input_data['estimated_finish_date'].dt.month\n",
    "\n",
    "        # Create a list to store predictions for each month\n",
    "        monthly_predictions = []\n",
    "\n",
    "        # Loop over range of dates from the current date to the estimated finish date with a step size of one month\n",
    "        current_date = pd.to_datetime(\"today\")\n",
    "        while current_date <= input_data['estimated_finish_date'].iloc[0]:\n",
    "            # Update features based on the current date\n",
    "            input_data['duration_since_commencement'] = (current_date - input_data['actual_commencement_date']).dt.days\n",
    "            input_data['remaining_duration'] = (input_data['estimated_finish_date'] - current_date).dt.days\n",
    "            input_data['progress_ratio'] = input_data['duration_since_commencement'] / input_data['duration_until_estimated_finish']\n",
    "            input_data['days_exceeding_estimated_duration'] = input_data['duration_since_commencement'] - input_data['duration_until_estimated_finish']\n",
    "            input_data['is_delayed'] = (input_data['remaining_duration'] < 0).astype(int)\n",
    "\n",
    "            # Select relevant features\n",
    "            input_features = input_data[feature_columns]\n",
    "\n",
    "            # Predict using the trained model to get the probability of each stage\n",
    "            predicted_probs = gbm_model.predict_proba(input_features)[0]\n",
    "\n",
    "            # Get the most likely stage and the recommended materials\n",
    "            top_prediction_index = np.argmax(predicted_probs)\n",
    "            top_stage = label_to_stage_mapping[top_prediction_index]\n",
    "            top_probability = predicted_probs[top_prediction_index]\n",
    "            recommended_materials = materials_data.loc[materials_data['Activity'].str.contains(top_stage, case=False, na=False), 'Materials (suggestions)']\n",
    "            recommended_materials = recommended_materials.values[0] if not recommended_materials.empty else \"No materials suggested\"\n",
    "\n",
    "            # Append the prediction for the current date to the list of monthly predictions\n",
    "            monthly_predictions.append({\n",
    "                \"Date\": current_date.strftime('%Y-%m-%d'),\n",
    "                \"Stage\": top_stage,\n",
    "                \"Probability\": top_probability,\n",
    "                \"Recommended Materials\": recommended_materials\n",
    "            })\n",
    "\n",
    "            # Move to the next month\n",
    "            current_date = current_date + MonthEnd(1)\n",
    "\n",
    "        return monthly_predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting current stage: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test the prediction function with a sample input\n",
    "test_input = {\n",
    "    \"actual_commencement_date\": \"2023-08-21\",\n",
    "    \"estimated_finish_date\": \"2024-12-03\",\n",
    "}\n",
    "\n",
    "results = predict_current_stage(test_input, feature_columns, gbm_model, label_to_stage_mapping, materials_data)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90876802-9fdf-45e4-8862-d41eef214628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "def predict_current_stage(inputs, feature_columns, gbm_model, label_to_stage_mapping, materials_data):\n",
    "    try:\n",
    "        # Creating a dataframe from the inputs\n",
    "        input_data = pd.DataFrame([inputs])\n",
    "\n",
    "        # Convert date columns to datetime objects\n",
    "        input_data['actual_commencement_date'] = pd.to_datetime(input_data['actual_commencement_date'])\n",
    "        input_data['estimated_finish_date'] = pd.to_datetime(input_data['estimated_finish_date'])\n",
    "\n",
    "        # Initialize features that do not change within the loop\n",
    "        input_data['duration_until_estimated_finish'] = (input_data['estimated_finish_date'] - input_data['actual_commencement_date']).dt.days\n",
    "        input_data['year_of_commencement'] = input_data['actual_commencement_date'].dt.year\n",
    "        input_data['month_of_commencement'] = input_data['actual_commencement_date'].dt.month\n",
    "        input_data['year_of_estimated_finish'] = input_data['estimated_finish_date'].dt.year\n",
    "        input_data['month_of_estimated_finish'] = input_data['estimated_finish_date'].dt.month\n",
    "\n",
    "        # Create a list to store predictions for each month\n",
    "        monthly_predictions = []\n",
    "\n",
    "        # Loop over range of dates from the current date to the estimated finish date with a step size of one month\n",
    "        current_date = pd.to_datetime(\"today\")\n",
    "        while current_date <= input_data['estimated_finish_date'].iloc[0]:\n",
    "            # Update features based on the current date\n",
    "            input_data['duration_since_commencement'] = (current_date - input_data['actual_commencement_date']).dt.days\n",
    "            input_data['remaining_duration'] = (input_data['estimated_finish_date'] - current_date).dt.days\n",
    "            input_data['progress_ratio'] = input_data['duration_since_commencement'] / input_data['duration_until_estimated_finish']\n",
    "            input_data['days_exceeding_estimated_duration'] = input_data['duration_since_commencement'] - input_data['duration_until_estimated_finish']\n",
    "            input_data['is_delayed'] = (input_data['remaining_duration'] < 0).astype(int)\n",
    "\n",
    "            # Select relevant features\n",
    "            input_features = input_data[feature_columns]\n",
    "\n",
    "            # Predict using the trained model to get the probability of each stage\n",
    "            predicted_probs = gbm_model.predict_proba(input_features)[0]\n",
    "\n",
    "            # Get the most likely stage and the recommended materials\n",
    "            top_prediction_index = np.argmax(predicted_probs)\n",
    "            top_stage = label_to_stage_mapping[top_prediction_index]\n",
    "            top_probability = predicted_probs[top_prediction_index]\n",
    "            recommended_materials = materials_data.loc[materials_data['Activity'].str.contains(top_stage, case=False, na=False), 'Materials (suggestions)']\n",
    "            recommended_materials = recommended_materials.values[0] if not recommended_materials.empty else \"No materials suggested\"\n",
    "\n",
    "            # Append the prediction for the current date to the list of monthly predictions\n",
    "            monthly_predictions.append({\n",
    "                \"Date\": current_date.strftime('%Y-%m-%d'),\n",
    "                \"Stage\": top_stage,\n",
    "                \"Probability\": top_probability,\n",
    "                \"Recommended Materials\": recommended_materials\n",
    "            })\n",
    "\n",
    "            # Move to the next month\n",
    "            current_date = current_date + MonthEnd(1)\n",
    "\n",
    "        return monthly_predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting current stage: {e}\")\n",
    "        return []\n",
    "\n",
    "test_input = {\n",
    "    \"actual_commencement_date\": \"2023-06-28\",\n",
    "    \"estimated_finish_date\": \"2024-12-03\",\n",
    "}\n",
    "\n",
    "results = predict_current_stage(test_input, feature_columns, gbm_model, label_to_stage_mapping, materials_data)\n",
    "df_results = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "899949e8-eae3-43c4-bcc3-776bd318a85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_buffer = StringIO()\n",
    "df_results.to_csv(csv_buffer, index=False)\n",
    "def upload_buffer_to_s3(bucket_name, file_name, buffer):\n",
    "    try:\n",
    "        s3 = boto3.resource('s3')\n",
    "        s3.Object(bucket_name, file_name).put(Body=buffer.getvalue())\n",
    "        print(f\"File {file_name} uploaded successfully to {bucket_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading buffer to S3: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0ae5ba8-95c6-4613-b1b3-360eaacb9a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File foryouvijitamam_results.csv uploaded successfully to demomlbucket202.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"demomlbucket202\"   # Replace with your S3 bucket name\n",
    "file_name_in_s3 = \"foryouvijitamam_results.csv\"\n",
    "upload_buffer_to_s3(bucket_name, file_name_in_s3, csv_buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833f703-30ed-474c-8cd8-27a70760f2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
